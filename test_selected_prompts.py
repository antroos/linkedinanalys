#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –ø—Ä–æ–º–ø—Ç–æ–≤ OpenAI GPT-4 Vision –Ω–∞ –Ω–æ–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
"""

import requests
import base64
import json
import os
from pathlib import Path

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è OpenAI (–∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_API_URL = "https://api.openai.com/v1/chat/completions"

# –ù–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
IMAGE_PATH = "screenshot_2025-07-15T13-58-11-498Z.jpg"

# –í—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã (1, 5, 7, 8, 9, 10)
SELECTED_PROMPTS = [
    {
        "id": 1,
        "text": "Extract all visible text from this image. List every word, number, and text element you can see."
    },
    {
        "id": 5,
        "text": "Analyze this image and extract all readable text, including any numbers, names, or labels."
    },
    {
        "id": 7,
        "text": "I need you to act as an OCR tool. Extract every piece of text visible in this image."
    },
    {
        "id": 8,
        "text": "This image contains text. Please read it all and provide a detailed transcription."
    },
    {
        "id": 9,
        "text": "Scan this image for text and provide a complete list of all visible words and text elements."
    },
    {
        "id": 10,
        "text": "Extract and list all text content from this image, maintaining the original formatting if possible."
    }
]

def test_selected_prompt(prompt_data):
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –Ω–∞ –Ω–æ–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    
    prompt_id = prompt_data["id"]
    prompt_text = prompt_data["text"]
    
    print(f"\nüî• –¢–ï–°–¢ #{prompt_id}")
    print(f"üìã –ü—Ä–æ–º–ø—Ç: '{prompt_text}'")
    print("=" * 100)
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not Path(IMAGE_PATH).exists():
            print(f"‚ùå –§–∞–π–ª {IMAGE_PATH} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
            return False, ""
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        with open(IMAGE_PATH, "rb") as f:
            image_data = f.read()
        
        # –ö–æ–¥–∏—Ä—É–µ–º –≤ base64
        img_b64 = base64.b64encode(image_data).decode('utf-8')
        print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {len(image_data)} –±–∞–π—Ç, base64: {len(img_b64)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {OPENAI_API_KEY}"
        }
        
        # Payload –¥–ª—è OpenAI Vision API
        payload = {
            "model": "gpt-4o",
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt_text
                        },
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{img_b64}"
                            }
                        }
                    ]
                }
            ],
            "max_tokens": 1500,
            "temperature": 0.1
        }
        
        print("üöÄ –û—Ç–ø—Ä–∞–≤–ª—è—é –∑–∞–ø—Ä–æ—Å –∫ OpenAI...")
        response = requests.post(
            OPENAI_API_URL,
            headers=headers,
            json=payload,
            timeout=45
        )
        
        print(f"üì° HTTP —Å—Ç–∞—Ç—É—Å: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            
            if 'choices' in result and result['choices']:
                content = result['choices'][0]['message']['content'].strip()
                tokens = result.get('usage', {}).get('completion_tokens', 0)
                
                print(f"‚úÖ –£–°–ü–ï–•!")
                print(f"üìä –¢–æ–∫–µ–Ω–æ–≤: {tokens}")
                print(f"üìù –û—Ç–≤–µ—Ç GPT-4:")
                print("‚îÄ" * 100)
                print(content)
                print("‚îÄ" * 100)
                
                return True, content
                    
            else:
                print(f"‚ùå –ù–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –≤ –æ—Ç–≤–µ—Ç–µ")
                print(f"üìÑ –ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç: {json.dumps(result, indent=2, ensure_ascii=False)}")
                
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ {response.status_code}")
            print(f"üìÑ –û—Ç–≤–µ—Ç: {response.text}")
            
    except Exception as e:
        print(f"üí• –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: {e}")
    
    return False, ""

def main():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –Ω–∞ –Ω–æ–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏"""
    
    print("üéØ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –í–´–ë–†–ê–ù–ù–´–• –ü–†–û–ú–ü–¢–û–í –ù–ê –ù–û–í–û–ú –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–ò")
    print(f"üñºÔ∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {IMAGE_PATH}")
    print(f"üîó API: {OPENAI_API_URL}")
    print(f"üìù –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º–ø—Ç–æ–≤: {len(SELECTED_PROMPTS)}")
    print("=" * 120)
    
    results = []
    
    for prompt_data in SELECTED_PROMPTS:
        success, response_text = test_selected_prompt(prompt_data)
        if success:
            results.append((prompt_data["id"], prompt_data["text"], response_text))
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        import time
        time.sleep(2)
    
    # –ò—Ç–æ–≥–∏
    print("\n" + "=" * 120)
    print("üèÜ –ò–¢–û–ì–û–í–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´")
    print("=" * 120)
    
    if results:
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {len(results)} –∏–∑ {len(SELECTED_PROMPTS)}")
        
        for prompt_id, prompt_text, response in results:
            print(f"\nüéØ –ü–†–û–ú–ü–¢ #{prompt_id} - –£–°–ü–ï–•")
            print(f"   –¢–µ–∫—Å—Ç: '{prompt_text[:80]}{'...' if len(prompt_text) > 80 else ''}'")
            print(f"   –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(response)} —Å–∏–º–≤–æ–ª–æ–≤")
    else:
        print("‚ùå –ù–∏ –æ–¥–∏–Ω —Ç–µ—Å—Ç –Ω–µ –¥–∞–ª —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞")

if __name__ == "__main__":
    main() 